import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import plotly.express as px
import pydeck as pdk

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
st.set_page_config(page_title="Traffy Fondue Explorer (Auto Map)", layout="wide")

st.title("üö¶ Traffy Fondue Analytics (Cluster & Heatmap & Prediction)")

# =========================================================
# 1. Config & Data Loading
# =========================================================

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏à‡∏≠‡πÉ‡∏ô CSV (Key = ‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î, Value = ‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏ô CSV)
REQUIRED_COLS_CONFIG = {
    'ticket_id': '‡∏£‡∏´‡∏±‡∏™‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á (ID)',
    'comment': '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤',
    'organization_1': '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô (Organization)',
    'organization_2': '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô (Organization)', # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢ format
    'organization_3': '‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô (Organization)',
    'type 1': '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (Type)',
    'type 2': '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (Type)',
    'type 3': '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (Type)',
    'count_reopen': '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡∏ã‡πâ‡∏≥ (Reopen)',
    'star': '‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô (Star)',
    'timestamp': '‡∏ß‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏à‡πâ‡∏á (Timestamp)',
    'province': '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î',
    'district': '‡πÄ‡∏Ç‡∏ï/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠',
    'subdistrict': '‡πÅ‡∏Ç‡∏ß‡∏á/‡∏ï‡∏≥‡∏ö‡∏•',
    'state': '‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ (State)',
    'latitude': '‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î (Latitude)',
    'longitude': '‡∏•‡∏≠‡∏á‡∏à‡∏¥‡∏à‡∏π‡∏î (Longitude)',
    'cluster': '‡∏Å‡∏•‡∏∏‡πà‡∏° (Cluster)'
}

@st.cache_data
def load_raw_data():
    try:
        return pd.read_csv('scrape.csv')
    except FileNotFoundError:
        try:
            return pd.read_csv('scrape.csv')
        except FileNotFoundError:
            return pd.DataFrame()

raw_df = load_raw_data()

@st.cache_data
def load_cluster_df():
    return pd.read_csv("clusterd_df.csv")
clusterd_df = load_cluster_df()

if raw_df.empty:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å (merged_data.csv ‡∏´‡∏£‡∏∑‡∏≠ clean_data2.csv)")
    st.stop()

# =========================================================
# 1.1 Auto Mapping Logic (‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà UI ‡πÄ‡∏î‡∏¥‡∏°)
# =========================================================

# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Dictionary ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠ ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠
rename_dict = {}
found_cols = []

# ‡∏•‡∏π‡∏õ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏≤‡∏° Config
for internal_name, csv_header in REQUIRED_COLS_CONFIG.items():
    if csv_header in raw_df.columns:
        # ‡∏Å‡∏£‡∏ì‡∏µ 1: ‡πÄ‡∏à‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πä‡∏∞‡πÜ ‡πÉ‡∏ô CSV -> ‡∏™‡∏±‡πà‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠
        rename_dict[csv_header] = internal_name
        found_cols.append(internal_name)
    elif internal_name in raw_df.columns:
        # ‡∏Å‡∏£‡∏ì‡∏µ 2: CSV ‡∏ñ‡∏π‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß -> ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
        found_cols.append(internal_name)

# ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
df = raw_df.rename(columns=rename_dict)

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå
df = df[found_cols]

# ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Ñ‡∏£‡∏ö‡πÑ‡∏´‡∏°
missing_critical = []
for crit in ['latitude', 'longitude']:
    if crit not in df.columns:
        missing_critical.append(crit)

if missing_critical:
    st.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏û‡∏¥‡∏Å‡∏±‡∏î: {missing_critical} ‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏≤‡∏à‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV)")

# --- Process Data ---

# ‡πÅ‡∏õ‡∏•‡∏á Timestamp
if 'timestamp' in df.columns:
    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
    if pd.api.types.is_datetime64_any_dtype(df['timestamp']):
        if df['timestamp'].dt.tz is not None:
             df['timestamp'] = df['timestamp'].dt.tz_localize(None)

# ‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Map)
for col in ['latitude', 'longitude', 'star', 'count_reopen', 'cluster']:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')

# =========================================================
# 2. Sidebar Filters
# =========================================================
st.sidebar.header("üîç ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1 & 2)")

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà ---
st.sidebar.markdown("---")
# ---------------------------------------------

if df.empty:
    st.error("‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
    st.stop()

# Filter Input
n_sample = st.sidebar.slider("1. ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (Sample)", 1, 10000, min(1000, len(df)))

# ‡πÉ‡∏ä‡πâ get ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô Error ‡∏Å‡∏£‡∏ì‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏°‡πà‡∏°‡∏µ
org_options = []
if 'organization_1' in df.columns: 
    org_options = df['organization_1'].dropna().unique()
selected_org = st.sidebar.multiselect("2. ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô", org_options)

type_options = []
if 'type 1' in df.columns:
    type_options = df['type 1'].dropna().unique()
selected_type = st.sidebar.multiselect("3. ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤", type_options)

max_reopen = int(df['count_reopen'].max()) if 'count_reopen' in df.columns and not pd.isna(df['count_reopen'].max()) else 10
reopen_range = st.sidebar.slider("4. ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏õ‡∏¥‡∏î‡∏ã‡πâ‡∏≥", 0, max_reopen, (0, max_reopen))

star_range = st.sidebar.slider("5. ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô (Star)", 0, 5, (0, 5))

if 'timestamp' in df.columns and not df['timestamp'].isna().all():
    min_date = df['timestamp'].min()
    max_date = df['timestamp'].max()
else:
    min_date = datetime.now()
    max_date = datetime.now()
    
date_range = st.sidebar.date_input("6. ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", [min_date, max_date])

selected_prov = st.sidebar.multiselect("7. ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", df['province'].dropna().unique() if 'province' in df.columns else [])
selected_dist = st.sidebar.multiselect("8. ‡πÄ‡∏Ç‡∏ï/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠", df['district'].dropna().unique() if 'district' in df.columns else [])
selected_sub = st.sidebar.multiselect("9. ‡πÅ‡∏Ç‡∏ß‡∏á/‡∏ï‡∏≥‡∏ö‡∏•", df['subdistrict'].dropna().unique() if 'subdistrict' in df.columns else [])
selected_state = st.sidebar.multiselect("10. ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞", df['state'].dropna().unique() if 'state' in df.columns else [])

# =========================================================
# NEW SIDEBAR SECTION: Prediction Settings
# =========================================================
st.sidebar.markdown("---")
st.sidebar.header("üîÆ ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3)")
n_pred_sample = st.sidebar.slider("1. ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (Pred Sample)", 1, 20000, 2000, help="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ô‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")
pred_dot_size = st.sidebar.slider("2. ‡∏Ç‡∏ô‡∏≤‡∏î‡∏à‡∏∏‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (Max Dot Size)", 5, 50, 15, help="‡∏Ç‡∏ô‡∏≤‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏ß‡∏á‡∏Å‡∏•‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")

# --- Filtering Logic ---
filtered_df = df.copy()

# Filter Organization (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
if selected_org:
    org_conditions = False
    if 'organization_1' in filtered_df.columns:
        org_conditions = org_conditions | filtered_df['organization_1'].isin(selected_org)
    if 'organization_2' in filtered_df.columns:
        org_conditions = org_conditions | filtered_df['organization_2'].isin(selected_org)
    if 'organization_3' in filtered_df.columns:
        org_conditions = org_conditions | filtered_df['organization_3'].isin(selected_org)
    
    if isinstance(org_conditions, pd.Series):
        filtered_df = filtered_df[org_conditions]

# Filter Type (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
if selected_type:
    type_conditions = False
    if 'type 1' in filtered_df.columns:
        type_conditions = type_conditions | filtered_df['type 1'].isin(selected_type)
    if 'type 2' in filtered_df.columns:
        type_conditions = type_conditions | filtered_df['type 2'].isin(selected_type)
    if 'type 3' in filtered_df.columns:
        type_conditions = type_conditions | filtered_df['type 3'].isin(selected_type)
        
    if isinstance(type_conditions, pd.Series):
        filtered_df = filtered_df[type_conditions]

    if 'first_type' in clusterd_df.columns:
        clusterd_df = clusterd_df[clusterd_df['first_type'].isin(selected_type)]


if 'count_reopen' in filtered_df.columns:
    filtered_df = filtered_df[filtered_df['count_reopen'].between(reopen_range[0], reopen_range[1])]
    clusterd_df = clusterd_df[clusterd_df['count_reopen'].between(reopen_range[0], reopen_range[1])]
if 'star' in filtered_df.columns:
    filtered_df = filtered_df[filtered_df['star'].between(star_range[0], star_range[1])]

if 'timestamp' in filtered_df.columns and isinstance(date_range, tuple) and len(date_range) == 2:
    start_date = pd.to_datetime(date_range[0])
    end_date = pd.to_datetime(date_range[1]) + timedelta(days=1) - timedelta(seconds=1)
    filtered_df = filtered_df[(filtered_df['timestamp'] >= start_date) & (filtered_df['timestamp'] <= end_date)]

if selected_prov: filtered_df = filtered_df[filtered_df['province'].isin(selected_prov)]

if selected_dist: filtered_df = filtered_df[filtered_df['district'].isin(selected_dist)]
if selected_dist: clusterd_df = clusterd_df[clusterd_df['district'].isin(selected_dist)]

if selected_sub: filtered_df = filtered_df[filtered_df['subdistrict'].isin(selected_sub)]

if selected_state: filtered_df = filtered_df[filtered_df['state'].isin(selected_state)]
if selected_state: clusterd_df = clusterd_df[clusterd_df['state'].isin(selected_state)]

# ‡πÅ‡∏¢‡∏Å Dataframe
plot_df = filtered_df
display_df = filtered_df.head(n_sample)
clusterd_df_display = clusterd_df.head(n_sample)

st.markdown(f"**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏û‡∏ö (Filter):** {len(plot_df):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ | **‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•:** {len(display_df):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
st.markdown("---")

# =========================================================
# 3. Visualization (Separated Maps - Original)
# =========================================================

st.header("1. ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡∏≤‡πÅ‡∏ô‡πà‡∏ô (Map Visualization)")

# ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡∏´‡πâ‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏á ‡∏´‡πâ‡∏≤‡∏° NaN)
if 'latitude' in display_df.columns and 'longitude' in display_df.columns:
    map_data = display_df.dropna(subset=['latitude', 'longitude'])
    # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡πà‡∏≤ 0 ‡∏≠‡∏≠‡∏Å
    map_data = map_data[(map_data['latitude'] != 0) & (map_data['longitude'] != 0)]
else:
    map_data = pd.DataFrame()

if not map_data.empty:
    mid_lat = map_data['latitude'].mean()
    mid_lon = map_data['longitude'].mean()

    # View State ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    view_state = pdk.ViewState(
        latitude=mid_lat,
        longitude=mid_lon,
        zoom=10,
        pitch=0,
    )

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Tabs ‡πÅ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô
    tab_scatter, tab_heat, tab_cluster = st.tabs(["üìç Scatter Plot (‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î)", "üî• Heatmap (‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡πâ‡∏≠‡∏ô)", "Cluster (‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°)"])

    # ---------------- TAB 1: SCATTER ----------------
    with tab_scatter:
        st.caption("‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏à‡∏∏‡∏î")
        
        map_data['color'] = [[255, 0, 0, 180]] * len(map_data)

        scatterplot_layer = pdk.Layer(
            "ScatterplotLayer",
            data=map_data,
            get_position='[longitude, latitude]',
            get_fill_color='color',
            get_radius=50,
            pickable=True,
            opacity=0.8,
            stroked=True,
            filled=True,
            radius_min_pixels=3,
            radius_max_pixels=10,
        )

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Tooltip HTML ‡πÅ‡∏ö‡∏ö Dynamic (‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏´‡∏ô‡∏ö‡πâ‡∏≤‡∏á)
        tooltip_fields = []
        if 'ticket_id' in map_data.columns: tooltip_fields.append("<b>ID:</b> {ticket_id}")
        if 'type 1' in map_data.columns: tooltip_fields.append("<b>Type:</b> {type 1}")
        if 'type 2' in map_data.columns: tooltip_fields.append("<b>Type:</b> {type 2}")
        if 'type 3' in map_data.columns: tooltip_fields.append("<b>Type:</b> {type 3}")
        if 'cluster' in map_data.columns: tooltip_fields.append("<b>Cluster:</b> {cluster}")
        
        tooltip_html = {
            "html": "<br/>".join(tooltip_fields) if tooltip_fields else "No Info",
            "style": {"backgroundColor": "steelblue", "color": "white"}
        }

        st.pydeck_chart(pdk.Deck(
            layers=[scatterplot_layer], 
            initial_view_state=view_state,
            tooltip=tooltip_html
        ))

    # ---------------- TAB 2: HEATMAP ----------------
    with tab_heat:
        st.caption("‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡∏≤‡πÅ‡∏ô‡πà‡∏ô (Heatmap)")
        
        heatmap_layer = pdk.Layer(
            "HeatmapLayer",
            data=map_data,
            get_position='[longitude, latitude]',
            get_fill_color='color',
            opacity=0.8,
            aggregation_name="SUM",
            radiusPixels=40,    
            intensity=1,
            threshold=0.05      
        )

        st.pydeck_chart(pdk.Deck(
            layers=[heatmap_layer], 
            initial_view_state=view_state
        ))

    with tab_cluster:
        def get_color(cluster_id):
            if cluster_id == 1:
                return [255, 0, 0, 200]    # ‡∏™‡∏µ‡πÅ‡∏î‡∏á (Cluster 1)
            elif cluster_id == 2:
                return [0, 255, 0, 200]    # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß (Cluster 2)
            elif cluster_id == 3:
                return [0, 0, 255, 200]    # ‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô (Cluster 3)
            else:
                return [165, 3, 252, 200] # ‡∏™‡∏µ‡πÄ‡∏ó‡∏≤ (‡∏≠‡∏∑‡πà‡∏ô‡πÜ)

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏µ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô DataFrame
        clusterd_df_display['color'] = clusterd_df_display['cluster'].apply(get_color)

        # 3. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà
        view_state = pdk.ViewState(
            latitude=clusterd_df_display['latitude'].mean(),
            longitude=clusterd_df_display['longitude'].mean(),
            zoom=11,
            pitch=0
        )

        # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á Scatterplot Layer
        scatterplot_layer = pdk.Layer(
            "ScatterplotLayer",
            data=clusterd_df_display,
            get_position='[longitude, latitude]',
            get_fill_color='color',      # ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á
            get_radius=200,              # ‡∏£‡∏±‡∏®‡∏°‡∏µ‡∏Ç‡∏≠‡∏á‡∏à‡∏∏‡∏î (‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏°‡∏ï‡∏£)
            radius_min_pixels=5,         # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠
            radius_max_pixels=50,
            pickable=True,               # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å! ‡∏ï‡πâ‡∏≠‡∏á True ‡∏ñ‡∏∂‡∏á‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á Tooltip ‡πÑ‡∏î‡πâ
            opacity=0.8,
            stroked=True,
            filled=True
        )

        # 5. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤ Tooltip
        tooltip = {
            "html": "<b>‡πÄ‡∏Ç‡∏ï:</b> {district} <br/>"
                    "<b>Cluster:</b> {cluster} <br/>"
                    "<b>‡∏õ‡∏±‡∏ç‡∏´‡∏≤:</b> {first_type} <br/>"
                    "<b>‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞:</b> {state} <br/>"
                    "<b>Reopen:</b> {count_reopen}",
            "style": {
                "backgroundColor": "steelblue",
                "color": "white"
            }
        }

        st.caption("‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏∏‡∏î‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏° (Cluster)")

        # 6. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
        st.pydeck_chart(pdk.Deck(
            initial_view_state=view_state,
            layers=[scatterplot_layer],
            tooltip=tooltip
        ))


else:
    st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¥‡∏Å‡∏±‡∏î (Latitude/Longitude) ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô 0 ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å")
    
st.markdown("---")

st.header("2. ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß")

col1, col2 = st.columns(2)
target_cols = ['subdistrict', 'district', 'province', 'state', 'star', 'count_reopen']

for i, col_name in enumerate(target_cols):
    with (col1 if i % 2 == 0 else col2):
        if col_name in plot_df.columns:
            if plot_df[col_name].notna().sum() > 0:
                fig = px.histogram(
                    plot_df, 
                    x=col_name, 
                    title=f"‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á {col_name}",
                    color_discrete_sequence=['#636EFA']
                )
                st.plotly_chart(fig, use_container_width=True)

st.markdown("---")

st.markdown("---")

# =========================================================
# NEW SECTION: Cluster Analysis (Updated with Count Chart)
# =========================================================
st.header("3. ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (Cluster Analysis)")

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Cluster ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
# ‡πÉ‡∏ä‡πâ plot_df ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£ filter ‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß
if 'cluster' in clusterd_df.columns:
    # ‡πÅ‡∏õ‡∏•‡∏á Cluster ‡πÄ‡∏õ‡πá‡∏ô String ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏µ‡πÅ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô (Discrete Color)
    cluster_data = clusterd_df.copy()
    cluster_data['cluster'] = cluster_data['cluster'].astype(str)
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠ Cluster (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏° 0, 1, 2...)
    unique_clusters = sorted([c for c in cluster_data['cluster'].unique() if c != 'nan' and c != 'None'], key=lambda x: int(float(x)) if x.replace('.','',1).isdigit() else x)

    # -------------------------------------------------------
    # 3.1 ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Cluster (‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà‡∏ï‡∏≤‡∏°‡∏Ç‡∏≠)
    # -------------------------------------------------------
    st.subheader("3.1 ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Cluster")

    # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô
    total_counts = cluster_data.groupby('cluster').size().reset_index(name='count')
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏° Cluster ID
    total_counts = total_counts.sort_values('cluster', key=lambda col: col.map(lambda x: int(float(x)) if x.replace('.','',1).isdigit() else x))
    
    fig_total = px.bar(
        total_counts, 
        x='cluster', 
        y='count', 
        color='cluster',
        title="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏° Cluster",
        labels={'cluster': 'Cluster', 'count': '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á'},
        text_auto=True
    )
    st.plotly_chart(fig_total, use_container_width=True)

    # -------------------------------------------------------
    # 3.2 Barchart ‡∏Ç‡∏≠‡∏á State (‡πÅ‡∏ö‡∏ö Grouped & Percentage) [Fix Logic]
    # -------------------------------------------------------
    st.subheader("3.2 ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô (‡∏Ñ‡∏¥‡∏î‡πÄ‡∏õ‡πá‡∏ô % ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Cluster)")
    
    # 1. ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô State ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° Cluster
    state_cluster_counts = cluster_data.groupby(['state', 'cluster']).size().reset_index(name='count')

    # 2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Total ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Cluster (‡∏´‡∏≤‡∏ú‡∏•‡∏£‡∏ß‡∏° count ‡∏Ç‡∏≠‡∏á cluster ‡∏ô‡∏±‡πâ‡∏ô‡πÜ)
    total_cluster_counts = state_cluster_counts.groupby('cluster')['count'].sum().reset_index(name='total_cluster_count')

    # 3. Merge ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• total ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å
    state_cluster_counts = pd.merge(state_cluster_counts, total_cluster_counts, on='cluster')

    # 4. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì % (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ô state / ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏ß‡∏°‡πÉ‡∏ô cluster * 100)
    state_cluster_counts['percentage'] = (state_cluster_counts['count'] / state_cluster_counts['total_cluster_count']) * 100
    
    # 5. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü
    fig_state_cluster = px.bar(
        state_cluster_counts, 
        x="state", 
        y="percentage",  
        color="cluster",
        title="‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô (% ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏†‡∏≤‡∏¢‡πÉ‡∏ô Cluster ‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á)",
        labels={
            "state": "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞", 
            "percentage": "‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô (%)", 
            "cluster": "Cluster",
            "count": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á",
            "total_cluster_count": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏ß‡∏°‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°"
        },
        barmode='group', 
        text_auto='.1f', 
        hover_data={'total_cluster_count': True, 'count': True, 'percentage': ':.2f'}
    )
    
    fig_state_cluster.update_layout(yaxis_ticksuffix="%")
    st.plotly_chart(fig_state_cluster, use_container_width=True)

    # -------------------------------------------------------
    # 3.3 Barchart ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ Count Reopen
    # -------------------------------------------------------
    st.subheader("3.3 ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡∏ã‡πâ‡∏≥ (Average Reopen) ‡∏£‡∏≤‡∏¢ Cluster")
    
    if 'count_reopen' in cluster_data.columns:
        avg_reopen = cluster_data.groupby('cluster')['count_reopen'].mean().reset_index()
        avg_reopen = avg_reopen.sort_values('cluster', key=lambda col: col.map(lambda x: int(float(x)) if x.replace('.','',1).isdigit() else x))

        fig_reopen = px.bar(
            avg_reopen,
            x='cluster',
            y='count_reopen',
            color='cluster',
            title="‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡∏ã‡πâ‡∏≥ (Reopen) ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Cluster",
            labels={'cluster': 'Cluster', 'count_reopen': '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏õ‡∏¥‡∏î‡∏ã‡πâ‡∏≥‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢'},
            text_auto='.2f'
        )
        st.plotly_chart(fig_reopen, use_container_width=True)

    # -------------------------------------------------------
    # 3.4 ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î Top 3 ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Cluster (Type & District)
    # -------------------------------------------------------
    st.subheader("3.4 ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î Top 3 ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡πÅ‡∏•‡∏∞ ‡πÄ‡∏Ç‡∏ï ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Cluster")
    
    if len(unique_clusters) > 0:
        # --- ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á Top 3 Type 1 ---
        st.markdown("##### üìå Top 3 ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (First Type)")
        cols_type = st.columns(len(unique_clusters)) 
        
        for i, cluster_id in enumerate(unique_clusters):
            with cols_type[i]:
                subset = cluster_data[cluster_data['cluster'] == cluster_id]
                # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ó‡∏±‡πâ‡∏á type 1 ‡πÅ‡∏•‡∏∞ first_type ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏ß‡∏£‡πå
                col_type_name = 'type 1' if 'type 1' in subset.columns else 'first_type'
                
                if col_type_name in subset.columns:
                    top_types = subset[col_type_name].value_counts().nlargest(3).reset_index()
                    top_types.columns = ['type', 'count']
                    
                    fig_type = px.bar(
                        top_types, x='type', y='count',
                        title=f"Cluster {cluster_id}", text_auto=True,
                        color_discrete_sequence=['#FF7F0E']
                    )
                    fig_type.update_layout(xaxis_title=None, yaxis_title=None, margin=dict(l=10, r=10, t=40, b=10))
                    st.plotly_chart(fig_type, use_container_width=True)

        # --- ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á Top 3 District ---
        st.markdown("##### üèôÔ∏è Top 3 ‡πÄ‡∏Ç‡∏ï (District)")
        cols_dist = st.columns(len(unique_clusters)) 
        
        for i, cluster_id in enumerate(unique_clusters):
            with cols_dist[i]:
                subset = cluster_data[cluster_data['cluster'] == cluster_id]
                if 'district' in subset.columns:
                    top_dists = subset['district'].value_counts().nlargest(3).reset_index()
                    top_dists.columns = ['district', 'count']
                    
                    fig_dist = px.bar(
                        top_dists, x='district', y='count',
                        title=f"Cluster {cluster_id}", text_auto=True,
                        color_discrete_sequence=['#2CA02C']
                    )
                    fig_dist.update_layout(xaxis_title=None, yaxis_title=None, margin=dict(l=10, r=10, t=40, b=10))
                    st.plotly_chart(fig_dist, use_container_width=True)

    # -------------------------------------------------------
    # 3.5 Top 3 ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (First Type) ‡πÅ‡∏¢‡∏Å‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏â‡∏û‡∏≤‡∏∞ (‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°)
    # -------------------------------------------------------
    st.subheader("3.5 ‡∏™‡∏£‡∏∏‡∏õ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (First Type) ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° Cluster")
    
    # ‡πÉ‡∏ä‡πâ logic ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡πÅ‡∏ï‡πà‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
    col_problem_name = 'type 1' # Default
    if 'first_type' in cluster_data.columns:
        col_problem_name = 'first_type'
    elif 'type 1' in cluster_data.columns:
        col_problem_name = 'type 1'
        
    if len(unique_clusters) > 0 and col_problem_name in cluster_data.columns:
        cols = st.columns(len(unique_clusters))
        
        for i, cluster_id in enumerate(unique_clusters):
            with cols[i]:
                subset = cluster_data[cluster_data['cluster'] == cluster_id]
                
                top_problems = subset[col_problem_name].value_counts().nlargest(3).reset_index()
                top_problems.columns = ['first_type', 'count']
                
                fig_prob = px.bar(
                    top_problems,
                    x='first_type',
                    y='count',
                    title=f"<b>Cluster {cluster_id}</b>",
                    text_auto=True,
                    color_discrete_sequence=['#FF5733'],
                    height=350
                )
                
                fig_prob.update_layout(
                    xaxis_title=None, 
                    yaxis_title=None, 
                    margin=dict(l=10, r=10, t=40, b=10),
                    showlegend=False
                )
                st.plotly_chart(fig_prob, use_container_width=True)

else:
    st.info("‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'cluster' ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏à‡∏∂‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÑ‡∏î‡πâ")

# =========================================================
# 5. NEW SECTION: Reopen Risk Visualization
# =========================================================
st.header("4. ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡∏ã‡πâ‡∏≥ (Reopen Risk Prediction)")
st.caption("‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå prediction_result.csv (‡∏™‡∏µ‡πÅ‡∏î‡∏á = ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á, ‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô = ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ï‡πà‡∏≥)")

# 5.1 Load Prediction Data
@st.cache_data
def load_prediction_data():
    try:
        # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå prediction_result.csv
        df_pred = pd.read_csv('prediction_results.csv')
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        required_pred_cols = ['latitude', 'longitude', 'reopen_probability', 'risk_level', 'ticket_id', 'type', 'district']
        missing_cols = [col for col in required_pred_cols if col not in df_pred.columns]
        
        if missing_cols:
             st.error(f"‚ùå ‡πÑ‡∏ü‡∏•‡πå prediction_result.csv ‡∏Ç‡∏≤‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô: {missing_cols}")
             return pd.DataFrame()
             
        return df_pred
    except FileNotFoundError:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå 'prediction_result.csv' ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")
        return pd.DataFrame()

pred_df = load_prediction_data()

# 5.2 Process & Plot Prediction Data
if not pred_df.empty:
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏≠‡∏á NaN
    pred_df['latitude'] = pd.to_numeric(pred_df['latitude'], errors='coerce')
    pred_df['longitude'] = pd.to_numeric(pred_df['longitude'], errors='coerce')
    pred_df = pred_df.dropna(subset=['latitude', 'longitude', 'reopen_probability'])
    
    # --- APPLY SLIDERS HERE ---
    # ‡πÉ‡∏ä‡πâ Slider ‡∏à‡∏≤‡∏Å Sidebar ‡∏°‡∏≤‡∏ï‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    pred_df = pred_df.head(n_pred_sample)
    
    if pred_df.empty:
         st.warning("‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Prediction ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¥‡∏Å‡∏±‡∏î (Latitude/Longitude) ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
    else:
        # ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏•‡πá‡∏≠‡∏ï
        st.info(f"üìç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•: {len(pred_df):,} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå) | ‡∏Ç‡∏ô‡∏≤‡∏î‡∏à‡∏∏‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {pred_dot_size}px")

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Scatter Mapbox ‡∏î‡πâ‡∏ß‡∏¢ Plotly Express
        # ‡πÉ‡∏ä‡πâ 'reopen_probability' ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏µ (Continuous Color Scale)
        # ‡∏™‡∏µ‡πÅ‡∏î‡∏á (Red) = ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏™‡∏π‡∏á, ‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô (Blue) = ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ï‡πà‡∏≥ (‡πÉ‡∏ä‡πâ RdBu_r reversed)
        fig_risk = px.scatter_mapbox(
            pred_df,
            lat="latitude",
            lon="longitude",
            color="reopen_probability", # ‡∏™‡∏µ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô
            size="reopen_probability",  # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô (‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏¢‡∏¥‡πà‡∏á‡πÉ‡∏´‡∏ç‡πà)
            hover_name="ticket_id",
            hover_data={
                "latitude": False,
                "longitude": False,
                "type": True,
                "risk_level": True,
                "district": True,
                "reopen_probability": ":.2f" # ‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏° 2 ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
            },
            color_continuous_scale=px.colors.sequential.RdBu_r, # ‡πÇ‡∏ó‡∏ô‡∏™‡∏µ ‡πÅ‡∏î‡∏á-‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô
            size_max=pred_dot_size, # <--- ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å Slider ‡∏Ç‡∏ô‡∏≤‡∏î‡∏à‡∏∏‡∏î‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
            zoom=10,
            height=600,
            title="‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏ñ‡∏π‡∏Å‡πÄ‡∏õ‡∏¥‡∏î‡∏ã‡πâ‡∏≥ (Reopen Risk Map)"
        )

        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏∏‡∏î‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà
        mid_lat_pred = pred_df['latitude'].mean()
        mid_lon_pred = pred_df['longitude'].mean()
        fig_risk.update_layout(
            mapbox_style="carto-positron", # ‡πÉ‡∏ä‡πâ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏ö‡∏ö‡∏™‡∏ß‡πà‡∏≤‡∏á
            mapbox_center={"lat": mid_lat_pred, "lon": mid_lon_pred},
            margin={"r":0,"t":40,"l":0,"b":0}
        )

        st.plotly_chart(fig_risk, use_container_width=True)

        # *** ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á Prediction ‡∏ñ‡∏π‡∏Å‡∏•‡∏ö‡∏≠‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏Ç‡∏≠ ***

st.markdown("---")